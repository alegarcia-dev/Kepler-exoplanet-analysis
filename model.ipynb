{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a977cb1e-48bb-4c00-94dd-caae5c34e780",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "This notebook contains all steps and decisions in the modeling phase of the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## The Required Imports\n",
    "\n",
    "Below are all the modules needed to run the code cells in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0c47424-7ed8-4812-bd76-d1b875d93ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from wrangle import wrangle_kepler_modeling\n",
    "from model import *\n",
    "from preprocessing import *\n",
    "from baseline import establish_classification_baseline\n",
    "from evaluate import *\n",
    "\n",
    "# We'll be using this random seed throughout.\n",
    "random_seed = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b826fa3-5b1b-4aad-aad0-d8ce0bcb0026",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Acquire, Prepare, and Split the Data\n",
    "\n",
    "Let's acquire, prepare, and split our data using the wrangle module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18877b7f-397e-438f-8702-8f42aa1516f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3376, 7), (1448, 7), (1207, 7))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = wrangle_kepler_modeling()\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf5149-3f05-48d3-ac2e-824ba6eafd15",
   "metadata": {},
   "source": [
    "Let's also scale our data while we're at it because chances are we're going to need the data to be scaled considering some features have extremely large values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6eae13-12ec-4dd1-a2f3-23042439dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate_scaled, test_scaled = scale_data(\n",
    "    train,\n",
    "    validate,\n",
    "    test,\n",
    "    train.drop(columns = 'disposition').columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a82408-bb20-4cd7-ae24-43fbca85a4bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A Note on Evaluation\n",
    "\n",
    "In this project we will be primarily be using accuracy to measure the performance of our models since there is a fairly even split between false positives and confirmed exoplanets. However, we will also make note of the recall scores in comparing model performance. In the case when two models have similar accuracy the precision score will help break the tie since we want to be sure of our positive predictions. When an observation is predicted as a confirmed exoplanet this would reasonably lead to prioritizing analysis of that object to verify the prediction. We want to be sure that this time spent analyzing an object will not be for nothing.\n",
    "\n",
    "Additionally, since we are interested primarily in identifying confirmed exoplanets more than false positive dispositions, the disposition of CONFIRMED will be our positive case and FALSE POSITIVE will be the negative (that's going to get confusing).\n",
    "\n",
    "## Establish a Baseline\n",
    "\n",
    "Before we can begin building models we have to establish a baseline model to compare our models to. This way we can determine if our models at least perform better than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414cd325-9bc3-431f-afce-8f5272d2ae30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3376,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = establish_classification_baseline(train.disposition)\n",
    "baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b8c8f4-ac08-439c-bef9-18e46a354d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALSE POSITIVE    3376\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "423a5803-3acc-4924-a3ed-f550358b355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make a baseline model for validate.\n",
    "# We'll use FALSE POSITIVE as the value the baseline model predicts because that was the value chosen \n",
    "# for the train baseline.\n",
    "validate_baseline = pd.Series('FALSE POSITIVE', index = validate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d1a539-2058-4d98-8613-cb411ce89e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALSE POSITIVE    1448\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_baseline.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615fdcf-e84d-47af-8cf9-a2af7523483b",
   "metadata": {},
   "source": [
    "Here the baseline is a model that always predicts an observation is a false positive since that is the most common value in the target variable. Let's evaluate the baseline model's performance before we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89316544-4167-4181-bcfc-59914bd1cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    **evaluate(train.disposition, baseline, 'CONFIRMED', prefix = 'train_'),\n",
    "    **evaluate(validate.disposition, validate_baseline, 'CONFIRMED', prefix = 'validate_')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef505de1-6a4c-4e39-afb2-46be0ce67f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_recall</th>\n",
       "      <th>validate_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_accuracy  train_recall  train_precision  validate_accuracy  \\\n",
       "Baseline        0.624111           0.0              0.0           0.623619   \n",
       "\n",
       "          validate_recall  validate_precision  \n",
       "Baseline              0.0                 0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = append_results('Baseline', results)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80b4a8-ae05-49a1-8161-538be4a60869",
   "metadata": {},
   "source": [
    "So our baseline has accuracy of 62% on both train and validate, and 0 for both recall and precision (which is expected).\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "Let's now use RFE to rank our features so that we can start with a few and add more features in the order they are ranked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc4512c-1dfe-442c-ae46-84e2b9ff403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=DecisionTreeClassifier(max_depth=3), n_features_to_select=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(DecisionTreeClassifier(max_depth = 3), n_features_to_select = 2)\n",
    "rfe.fit(train_scaled.drop(columns = 'disposition'), train_scaled.disposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e87a400-58ad-4ed4-8f75-aa5685291c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transit_depth</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>planetary_radius</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temperature</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normalized_depth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orbital_period</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transit_duration</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Var  Rank\n",
       "0     transit_depth     3\n",
       "1  planetary_radius     1\n",
       "2       temperature     5\n",
       "3  normalized_depth     2\n",
       "4    orbital_period     1\n",
       "5  transit_duration     4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Var': train_scaled.drop(columns = 'disposition').columns, 'Rank': rfe.ranking_})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd2cbd-827a-4839-9cfe-0efa26a37131",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create Some Models\n",
    "\n",
    "Now let's finally create some models to predict the exoplanet archive disposition. We'll start by creating a variety of models using different algorithms and our top two features chosen by RFE. For whichever provides the best performance we'll try a variety of different hyper-parameters and start adding on additional features and then choose our best model from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f2e77f-5b05-410c-ba06-e2ee69a4b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "    DecisionTreeClassifier(max_depth = 3, random_state = random_seed),\n",
    "    RandomForestClassifier(max_depth = 3, random_state = random_seed),\n",
    "    AdaBoostClassifier(random_state = random_seed),\n",
    "    BaggingClassifier(random_state = random_seed),\n",
    "    GradientBoostingClassifier(random_state = random_seed),\n",
    "    KNeighborsClassifier(),\n",
    "    SGDClassifier(random_state = random_seed),\n",
    "    BernoulliNB(),\n",
    "    SVC(random_state = random_seed)\n",
    "]\n",
    "\n",
    "features = ['planetary_radius', 'orbital_period']\n",
    "models = {}\n",
    "\n",
    "for key in range(1, len(algorithms) + 1):\n",
    "    models[key] = Model(algorithms[key - 1], train, features, 'disposition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ebffc6-f099-49fb-8bca-a1f96f9ce075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <model.Model at 0x7fc59f7f2bb0>,\n",
       " 2: <model.Model at 0x7fc59ab3a340>,\n",
       " 3: <model.Model at 0x7fc59ab248e0>,\n",
       " 4: <model.Model at 0x7fc59ab3a790>,\n",
       " 5: <model.Model at 0x7fc59ab3afa0>,\n",
       " 6: <model.Model at 0x7fc59ab24fa0>,\n",
       " 7: <model.Model at 0x7fc59ab249a0>,\n",
       " 8: <model.Model at 0x7fc59f7eb070>,\n",
       " 9: <model.Model at 0x7fc59f7cc1c0>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175919fa-31f9-4e7a-bdc3-6484a4b3b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_recall</th>\n",
       "      <th>validate_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.841825</td>\n",
       "      <td>0.901497</td>\n",
       "      <td>0.736639</td>\n",
       "      <td>0.832873</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>0.730594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.846564</td>\n",
       "      <td>0.878645</td>\n",
       "      <td>0.753888</td>\n",
       "      <td>0.830801</td>\n",
       "      <td>0.833028</td>\n",
       "      <td>0.746711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.846564</td>\n",
       "      <td>0.875493</td>\n",
       "      <td>0.755269</td>\n",
       "      <td>0.828039</td>\n",
       "      <td>0.838532</td>\n",
       "      <td>0.739482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.986374</td>\n",
       "      <td>0.988180</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.732049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.872334</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>0.806735</td>\n",
       "      <td>0.841160</td>\n",
       "      <td>0.803670</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.878851</td>\n",
       "      <td>0.866036</td>\n",
       "      <td>0.821375</td>\n",
       "      <td>0.822514</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.756228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.525474</td>\n",
       "      <td>0.116627</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.537983</td>\n",
       "      <td>0.150459</td>\n",
       "      <td>0.284722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli NB</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.730154</td>\n",
       "      <td>0.946414</td>\n",
       "      <td>0.587573</td>\n",
       "      <td>0.729972</td>\n",
       "      <td>0.950459</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_accuracy  train_recall  train_precision  \\\n",
       "Baseline                  0.624111      0.000000         0.000000   \n",
       "Decision Tree             0.841825      0.901497         0.736639   \n",
       "Random Forest             0.846564      0.878645         0.753888   \n",
       "Ada Boost                 0.846564      0.875493         0.755269   \n",
       "Bagging Classifier        0.986374      0.988180         0.975875   \n",
       "Gradient Boosting         0.872334      0.868400         0.806735   \n",
       "KNN                       0.878851      0.866036         0.821375   \n",
       "SGD                       0.525474      0.116627         0.235294   \n",
       "Bernoulli NB              0.624111      0.000000         0.000000   \n",
       "SVC                       0.730154      0.946414         0.587573   \n",
       "\n",
       "                    validate_accuracy  validate_recall  validate_precision  \n",
       "Baseline                     0.623619         0.000000            0.000000  \n",
       "Decision Tree                0.832873         0.880734            0.730594  \n",
       "Random Forest                0.830801         0.833028            0.746711  \n",
       "Ada Boost                    0.828039         0.838532            0.739482  \n",
       "Bagging Classifier           0.806630         0.766972            0.732049  \n",
       "Gradient Boosting            0.841160         0.803670            0.780749  \n",
       "KNN                          0.822514         0.779817            0.756228  \n",
       "SGD                          0.537983         0.150459            0.284722  \n",
       "Bernoulli NB                 0.623619         0.000000            0.000000  \n",
       "SVC                          0.729972         0.950459            0.587302  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\n",
    "    'Decision Tree',\n",
    "    'Random Forest',\n",
    "    'Ada Boost',\n",
    "    'Bagging Classifier',\n",
    "    'Gradient Boosting',\n",
    "    'KNN',\n",
    "    'SGD',\n",
    "    'Bernoulli NB',\n",
    "    'SVC'\n",
    "]\n",
    "\n",
    "for model, name in zip(models.values(), names):\n",
    "    eval_df = append_results(\n",
    "        name,\n",
    "        {\n",
    "            **evaluate(train.disposition, model.make_predictions(train), 'CONFIRMED', prefix = 'train_'),\n",
    "            **evaluate(validate.disposition, model.make_predictions(validate), 'CONFIRMED', prefix = 'validate_')\n",
    "        },\n",
    "        eval_df\n",
    "    )\n",
    "    \n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1225d89-802d-4ea7-af68-0488919f0c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_recall</th>\n",
       "      <th>validate_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.872334</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>0.806735</td>\n",
       "      <td>0.841160</td>\n",
       "      <td>0.803670</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.841825</td>\n",
       "      <td>0.901497</td>\n",
       "      <td>0.736639</td>\n",
       "      <td>0.832873</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>0.730594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.846564</td>\n",
       "      <td>0.878645</td>\n",
       "      <td>0.753888</td>\n",
       "      <td>0.830801</td>\n",
       "      <td>0.833028</td>\n",
       "      <td>0.746711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.846564</td>\n",
       "      <td>0.875493</td>\n",
       "      <td>0.755269</td>\n",
       "      <td>0.828039</td>\n",
       "      <td>0.838532</td>\n",
       "      <td>0.739482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.878851</td>\n",
       "      <td>0.866036</td>\n",
       "      <td>0.821375</td>\n",
       "      <td>0.822514</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.756228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.986374</td>\n",
       "      <td>0.988180</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.732049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.730154</td>\n",
       "      <td>0.946414</td>\n",
       "      <td>0.587573</td>\n",
       "      <td>0.729972</td>\n",
       "      <td>0.950459</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli NB</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.525474</td>\n",
       "      <td>0.116627</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.537983</td>\n",
       "      <td>0.150459</td>\n",
       "      <td>0.284722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_accuracy  train_recall  train_precision  \\\n",
       "Gradient Boosting         0.872334      0.868400         0.806735   \n",
       "Decision Tree             0.841825      0.901497         0.736639   \n",
       "Random Forest             0.846564      0.878645         0.753888   \n",
       "Ada Boost                 0.846564      0.875493         0.755269   \n",
       "KNN                       0.878851      0.866036         0.821375   \n",
       "Bagging Classifier        0.986374      0.988180         0.975875   \n",
       "SVC                       0.730154      0.946414         0.587573   \n",
       "Baseline                  0.624111      0.000000         0.000000   \n",
       "Bernoulli NB              0.624111      0.000000         0.000000   \n",
       "SGD                       0.525474      0.116627         0.235294   \n",
       "\n",
       "                    validate_accuracy  validate_recall  validate_precision  \n",
       "Gradient Boosting            0.841160         0.803670            0.780749  \n",
       "Decision Tree                0.832873         0.880734            0.730594  \n",
       "Random Forest                0.830801         0.833028            0.746711  \n",
       "Ada Boost                    0.828039         0.838532            0.739482  \n",
       "KNN                          0.822514         0.779817            0.756228  \n",
       "Bagging Classifier           0.806630         0.766972            0.732049  \n",
       "SVC                          0.729972         0.950459            0.587302  \n",
       "Baseline                     0.623619         0.000000            0.000000  \n",
       "Bernoulli NB                 0.623619         0.000000            0.000000  \n",
       "SGD                          0.537983         0.150459            0.284722  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.sort_values(by = 'validate_accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20070c8c-e261-4d1a-8237-633e3a13af61",
   "metadata": {},
   "source": [
    "Considering the performance on unseen data, Gradient Boosting has the best performance, and also not too much of a performance drop off from the train set either which is good news. We'll move forward with this algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "## Modifying the Hyper-Parameters\n",
    "\n",
    "Now let's try changing the hyper-parameters for gradient boosting to see if we can get better results that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddd496d5-b553-46bb-9c45-4a493746dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use loops to try a variety of hyper-parameters\n",
    "\n",
    "GBC_models = {}\n",
    "n = count()\n",
    "\n",
    "for loss in ['deviance', 'exponential']:\n",
    "    for n_estimators in range(100, 501, 50):\n",
    "        for max_depth in range(3, 11):\n",
    "            GBC_models[next(n)] = Model(\n",
    "                GradientBoostingClassifier(\n",
    "                    loss = loss,\n",
    "                    n_estimators = n_estimators,\n",
    "                    max_depth = max_depth,\n",
    "                    random_state = random_seed\n",
    "                ),\n",
    "                train,\n",
    "                features,\n",
    "                'disposition'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03d0b83a-fdb1-4af7-90f7-4bce3fae8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, model in enumerate(GBC_models.values()):\n",
    "    eval_df = append_results(\n",
    "        f'GBC_{index}',\n",
    "        {\n",
    "            **evaluate(train.disposition, model.make_predictions(train), 'CONFIRMED', prefix = 'train_'),\n",
    "            **evaluate(validate.disposition, model.make_predictions(validate), 'CONFIRMED', prefix = 'validate_')\n",
    "        },\n",
    "        eval_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5a8c827-135b-4681-86f5-9a64a80cc7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_recall</th>\n",
       "      <th>validate_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBC_104</th>\n",
       "      <td>0.894254</td>\n",
       "      <td>0.897557</td>\n",
       "      <td>0.833821</td>\n",
       "      <td>0.845304</td>\n",
       "      <td>0.811009</td>\n",
       "      <td>0.785080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC_40</th>\n",
       "      <td>0.917654</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.867309</td>\n",
       "      <td>0.843232</td>\n",
       "      <td>0.796330</td>\n",
       "      <td>0.789091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC_89</th>\n",
       "      <td>0.908175</td>\n",
       "      <td>0.912530</td>\n",
       "      <td>0.853353</td>\n",
       "      <td>0.842541</td>\n",
       "      <td>0.805505</td>\n",
       "      <td>0.782531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC_112</th>\n",
       "      <td>0.903436</td>\n",
       "      <td>0.907013</td>\n",
       "      <td>0.846946</td>\n",
       "      <td>0.841851</td>\n",
       "      <td>0.801835</td>\n",
       "      <td>0.783154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC_24</th>\n",
       "      <td>0.902844</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.849814</td>\n",
       "      <td>0.841160</td>\n",
       "      <td>0.794495</td>\n",
       "      <td>0.785844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.986374</td>\n",
       "      <td>0.988180</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.732049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.730154</td>\n",
       "      <td>0.946414</td>\n",
       "      <td>0.587573</td>\n",
       "      <td>0.729972</td>\n",
       "      <td>0.950459</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli NB</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.624111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.525474</td>\n",
       "      <td>0.116627</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.537983</td>\n",
       "      <td>0.150459</td>\n",
       "      <td>0.284722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_accuracy  train_recall  train_precision  \\\n",
       "GBC_104                   0.894254      0.897557         0.833821   \n",
       "GBC_40                    0.917654      0.921986         0.867309   \n",
       "GBC_89                    0.908175      0.912530         0.853353   \n",
       "GBC_112                   0.903436      0.907013         0.846946   \n",
       "GBC_24                    0.902844      0.900709         0.849814   \n",
       "...                            ...           ...              ...   \n",
       "Bagging Classifier        0.986374      0.988180         0.975875   \n",
       "SVC                       0.730154      0.946414         0.587573   \n",
       "Bernoulli NB              0.624111      0.000000         0.000000   \n",
       "Baseline                  0.624111      0.000000         0.000000   \n",
       "SGD                       0.525474      0.116627         0.235294   \n",
       "\n",
       "                    validate_accuracy  validate_recall  validate_precision  \n",
       "GBC_104                      0.845304         0.811009            0.785080  \n",
       "GBC_40                       0.843232         0.796330            0.789091  \n",
       "GBC_89                       0.842541         0.805505            0.782531  \n",
       "GBC_112                      0.841851         0.801835            0.783154  \n",
       "GBC_24                       0.841160         0.794495            0.785844  \n",
       "...                               ...              ...                 ...  \n",
       "Bagging Classifier           0.806630         0.766972            0.732049  \n",
       "SVC                          0.729972         0.950459            0.587302  \n",
       "Bernoulli NB                 0.623619         0.000000            0.000000  \n",
       "Baseline                     0.623619         0.000000            0.000000  \n",
       "SGD                          0.537983         0.150459            0.284722  \n",
       "\n",
       "[154 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.sort_values(by = 'validate_accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38b64a-b6ac-4e8b-82e9-6e105bcd930c",
   "metadata": {},
   "source": [
    "It looks like GBC_104 has a slightly better performance than the plain GBC algorithm. Let's see what the hyper-parameters were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36283e51-a171-435b-a03f-bcd49203988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', n_estimators=300,\n",
       "                           random_state=24)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC_models[104].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b77df5e-5575-4f09-90b2-ec54e7f4e2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validate_accuracy': 0.8453038674033149,\n",
       " 'validate_recall': 0.8110091743119267,\n",
       " 'validate_precision': 0.7850799289520426}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just verify this is the right one.\n",
    "evaluate(validate.disposition, GBC_models[104].make_predictions(validate), 'CONFIRMED', prefix = 'validate_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4f4bb-9b81-472d-a4e5-b28a9037410e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
